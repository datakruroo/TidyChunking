% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract_competencies.R
\name{extract_competencies_tidyllm}
\alias{extract_competencies_tidyllm}
\title{Extract Competencies Using TidyLLM}
\usage{
extract_competencies_tidyllm(
  chunks,
  max_per_chunk = 15,
  model = "gpt-4o-mini",
  custom_prompt = NULL,
  custom_schema = NULL
)
}
\arguments{
\item{chunks}{A tibble of chunks from \code{\link{chunk_for_keyword_extraction}}}

\item{max_per_chunk}{Maximum number of competencies to extract per chunk (default: 15)}

\item{model}{Model to use for extraction (default: "gpt-4o-mini")}

\item{custom_prompt}{Custom prompt text function. If NULL, uses default teacher competency prompt}

\item{custom_schema}{Custom tidyllm schema. If NULL, uses default competency schema}
}
\value{
A tibble with the following columns:
\describe{
  \item{term}{The competency term or phrase for teachers}
  \item{category}{Type of competency: "skill", "knowledge", "behavior", "tool", "practice", or "role"}
  \item{importance}{Importance level for classroom implementation: "high", "medium", or "low"}
  \item{definition}{Brief explanation of the competency in educational context}
  \item{source_chunk}{ID of the source chunk}
  \item{source_hierarchy}{Hierarchical path of the source chunk}
}
}
\description{
Extract data literacy competencies for graduate teachers to implement data-driven 
classroom practices from chunked text using Large Language Models via the tidyllm package. 
This function processes each chunk to identify relevant skills, knowledge, behaviors, 
tools, practices, and roles specifically for educational contexts.
}
\details{
This function requires the \code{tidyllm} and \code{jsonlite} packages.
It uses OpenAI's GPT-4o-mini model by default to extract competencies.

\strong{API Key Setup:}
Before using this function, you need to set up your OpenAI API key. The easiest way is to add it to your \code{.Renviron} file:
\preformatted{
# Add this line to your ~/.Renviron file
OPENAI_API_KEY="your-api-key-here"

# Restart R session after editing .Renviron
# You can edit .Renviron with: usethis::edit_r_environ()
}

Competency categories for data-driven classroom teaching:
\itemize{
  \item \strong{knowledge}: Concepts and theories teachers need to understand about data use in education
  \item \strong{skill}: Practical abilities teachers need to perform data-related tasks in classroom
  \item \strong{behavior}: Mindsets and approaches teachers should adopt for data-driven teaching
  \item \strong{tool}: Technologies and instruments teachers use for data collection and analysis
  \item \strong{practice}: Methods and procedures teachers follow in data-driven instruction
  \item \strong{role}: Responsibilities teachers have in data-driven educational settings
}

The function focuses on competencies that enable teachers to:
\itemize{
  \item Use data to improve student learning outcomes
  \item Make evidence-based instructional decisions
  \item Assess and analyze student performance data
  \item Create data-informed learning environments
}

\strong{Customization Options:}
\itemize{
  \item \code{model}: Choose different OpenAI models (e.g., "gpt-4", "gpt-4o", "gpt-3.5-turbo")
  \item \code{custom_prompt}: Provide your own prompt generation function for different domains
  \item \code{custom_schema}: Define your own extraction schema for different output formats
}

\strong{Custom Prompt Function:}
Your custom prompt function should accept parameters: \code{(n_comp, hier, text)} 
and return a string prompt.

\strong{Custom Schema:}
Use \code{tidyllm::tidyllm_schema()} to define your extraction structure.

\strong{Important}: This function extracts only competencies that are explicitly 
mentioned or directly implied in the source text. It does not generate new terms 
that are not present in the original content, ensuring accuracy and relevance to 
the specific document being analyzed.

The function automatically adjusts the number of competencies to extract
based on chunk size (roughly 1 competency per 50 words, capped at max_per_chunk).
}
\examples{
\dontrun{
# Setup: Add OPENAI_API_KEY to your .Renviron file first
# You can use: usethis::edit_r_environ()
# Then add: OPENAI_API_KEY="your-api-key-here"
# Restart R after editing .Renviron

# Requires tidyllm and jsonlite packages
if (require(tidyllm) && require(jsonlite)) {
  # Example with educational content
  educational_text <- "Teachers need to analyze student assessment data..."
  chunks <- chunk_for_keyword_extraction(educational_text)
  keyword_chunks <- filter_chunks_for_keywords(chunks)
  
  # Extract teacher competencies for data-driven classroom (default)
  teacher_competencies <- extract_competencies_tidyllm(keyword_chunks)
  
  # Use different model
  teacher_competencies_gpt4 <- extract_competencies_tidyllm(
    keyword_chunks, 
    model = "gpt-4"
  )
  
  # Custom prompt for business analysis
  business_prompt <- function(n_comp, hier, text) {
    paste0("Extract ", n_comp, " business skills from: ", text)
  }
  
  # Custom schema for different output
  business_schema <- tidyllm::tidyllm_schema(
    name = "business_extraction",
    skills = tidyllm::field_object(
      .vector = TRUE,
      skill = tidyllm::field_chr(.description = "Business skill"),
      level = tidyllm::field_fct(.levels = c("basic", "intermediate", "advanced"))
    )
  )
  
  business_skills <- extract_competencies_tidyllm(
    keyword_chunks,
    custom_prompt = business_prompt,
    custom_schema = business_schema
  )
  
  # View results
  head(teacher_competencies)
  table(teacher_competencies$category)
}
}

}
